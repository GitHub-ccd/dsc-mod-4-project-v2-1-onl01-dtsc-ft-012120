{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens recommendation project ##\n",
    "\n",
    "<img src=\"images/movies.jpg\" width=900>  \n",
    "\n",
    "<img src=\"images/recommender_systems.png\" width=875>  \n",
    "\n",
    "This project entails making movie recommendations via collaboration between user ratings and genre preferences. The dataset contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. The dataset consists of four csv files and a readme text file: links, movies, ratings, and tags with the following parameters:\n",
    "* movies.csv\n",
    "    * (9742, 3) rows/columns\n",
    "    * 'movieId', 'title', 'genres'\n",
    "\n",
    "* ratings.csv\n",
    "    * (100836, 4) rows/columns\n",
    "    * 'userId', 'movieId', 'rating', 'timestamp'\n",
    "\n",
    "* tags.csv\n",
    "    * (3683, 4) rows/columns\n",
    "    * 'userId', 'movieId', 'tag', 'timestamp'\n",
    "\n",
    "* links.csv\n",
    "    * (9742, 3) rows/columns\n",
    "    * 'movieId', 'imdbId', 'tmdbId'\n",
    "    \n",
    "* README.txt\n",
    "    * much like a dictionary\n",
    "    \n",
    ">*The performance metric used to gauge success in this notebook is the root mean squared error. (RMSE)*\n",
    "    \n",
    "This data set has the propensity to recommend the most popular films(population bias), since they're the ones receiving the vast majority of ratings, some older films have litte to no ratings at all. The maximum rating is 5, lowest 1, and the average hoovers at 3.5. This may be useful in addressing cold start issues when attempting to recommend films to new users. Sort of recommending the \"catch of the day\". \n",
    "```python\n",
    "ratings['rating'].describe()\n",
    "count    100836.000000\n",
    "mean          3.501557\n",
    "std           1.042529\n",
    "min           0.500000\n",
    "25%           3.000000\n",
    "50%           3.500000\n",
    "75%           4.000000\n",
    "max           5.000000\n",
    "Name: rating, dtype: float64\n",
    "```\n",
    "<img src=\"images/ratings_long_tail.png\" width= 575>  \n",
    "    \n",
    "**Similarity matrix's**\n",
    "\n",
    "*Pearson similarity matrix*\n",
    "```python\n",
    "# corr(pearson) method adjusts for the mean by default so no further need to standardize. \n",
    "pearson_similarity = user_ratings.corr(method='pearson')\n",
    "pearson_similarity.tail(5)\n",
    "```\n",
    "<img src=\"images/pearson.png\" width=575>  \n",
    "\n",
    "**User ratings based recommendations (pearson correlation matrix)**\n",
    "<img src=\"images/pearson-math.png\"> \n",
    "```python\n",
    "user = [('101 Dalmatians (1996)', 1), ('2001: A Space Odyssey (1968)', 4)]\n",
    "\n",
    "similar_movies = pd.DataFrame()\n",
    "    \n",
    "for movie, rating in user:\n",
    "    similar_movies = similar_movies.append(get_similar_movies(movie, rating), ignore_index = True)\n",
    "    \n",
    "similar_movies.sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "2001: A Space Odyssey (1968)                                                   1.333735\n",
    "Blade Runner (1982)                                                            0.822194\n",
    "Aliens (1986)                                                                  0.639186\n",
    "Clockwork Orange, A (1971)                                                     0.614576\n",
    "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)    0.603032\n",
    "Apocalypse Now (1979)                                                          0.586503\n",
    "Full Metal Jacket (1987)                                                       0.577457\n",
    "Platoon (1986)                                                                 0.549155\n",
    "Dark City (1998)                                                               0.541112\n",
    "Alien (1979)                                                                   0.537291\n",
    "```\n",
    "*Cosine similarity matrix*\n",
    "```python\n",
    "# to compute a similarity score three options are available: euclidean, correlation (pearson), and cosine\n",
    "tfV = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "tfV_matrix = tfV.fit_transform(movies['genres'])\n",
    "\n",
    "cosine_similarity = linear_kernel(tfV_matrix, tfV_matrix)\n",
    "```\n",
    "**Genre based recommendations**\n",
    "<img src=\"images/cosine.png\"> \n",
    "```python\n",
    "titles = movies['title']\n",
    "indices = pd.Series(movies.index, index=movies['title'])\n",
    "\n",
    "def genre_based_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    similarity_scores = list(enumerate(cosine_similarity[idx]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    similarity_scores = similarity_scores[1:11]\n",
    "    movie_indices = [i[0] for i in similarity_scores]\n",
    "\n",
    "    return titles.iloc[movie_indices]\n",
    "\n",
    "genre_based_recommendations('Zombieland (2009)')\n",
    "\n",
    "7154                                    Zombieland (2009)\n",
    "8434                                    Zombeavers (2014)\n",
    "8565                    Dead Snow 2: Red vs. Dead (2014) \n",
    "9035         Scouts Guide to the Zombie Apocalypse (2015)\n",
    "62                             From Dusk Till Dawn (1996)\n",
    "6251                             Snakes on a Plane (2006)\n",
    "6324                                         Feast (2005)\n",
    "11                     Dracula: Dead and Loving It (1995)\n",
    "654     Tales from the Crypt Presents: Bordello of Blo...\n",
    "1478                                      Gremlins (1984)\n",
    "```\n",
    "#### Future work:\n",
    "Deeper study into neural network recommendation systems through pytorch via Nvidia cuda (gpu processing) and tinkering with the various loss functions: mean absolute error, mean square error, smooth L1 loss, negative log-likeihood loss, cross-entropy loss, kullback-leibler divergence, marging ranking loss, hinge embedding loss, and cosine embedding loss. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
